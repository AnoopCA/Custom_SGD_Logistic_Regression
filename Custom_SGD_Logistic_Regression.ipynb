{"cells":[{"cell_type":"markdown","metadata":{"id":"7eiDWcM_MC3H"},"source":["Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn"]},{"cell_type":"markdown","metadata":{"id":"Fk5DSPCLxqT-"},"source":["Importing packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42Et8BKIxnsp"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import linear_model\n","from math import exp\n","from numpy import mean\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from numpy import inf\n","from mpmath import mp\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"NpSk3WQBx7TQ"},"source":["Creating custom dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsMp0oWzx6dv"},"outputs":[],"source":["# please don't change random_state\n","X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n","                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n","# make_classification is used to create custom dataset\n","# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8W2fg1cyGdX","outputId":"c22fa68a-9c69-48c9-e9a1-3e4ff16e80ae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((50000, 15), (50000,))"]},"metadata":{},"execution_count":85}],"source":["X.shape, y.shape"]},{"cell_type":"markdown","metadata":{"id":"x99RWCgpqNHw"},"source":["Splitting data into train and test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Kh4dBfVyJMP"},"outputs":[],"source":["#please don't change random state\n","# you need not standardize the data as it is already standardized\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DR_YMBsyOci","outputId":"ebc01464-a017-482b-e00f-8f56f7b59132"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((37500, 15), (37500,), (12500, 15), (12500,))"]},"metadata":{},"execution_count":87}],"source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"]},{"cell_type":"markdown","metadata":{"id":"BW4OHswfqjHR"},"source":["SGD classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HpvTwDHyQQy","outputId":"bcac06cd-ad8d-41e6-e7d7-7c9bfe3cdcc5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n","              random_state=15, verbose=2)"]},"metadata":{},"execution_count":4}],"source":["# alpha : float\n","# Constant that multiplies the regularization term.\n","\n","# eta0 : double\n","# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n","\n","clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n","clf\n","# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYaVyQ2lyXcr"},"outputs":[],"source":["clf.fit(X=X_train, y=y_train) # fitting our model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EAfkVI6GyaRO","outputId":"76e497ee-82fb-44ac-ffb2-5257f3081fb4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n","          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n","          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n"," (1, 15),\n"," array([-0.8531383]))"]},"metadata":{},"execution_count":90}],"source":["clf.coef_, clf.coef_.shape, clf.intercept_\n","#clf.coef_ will return the weights\n","#clf.coef_.shape will return the shape of weights\n","#clf.intercept_ will return the intercept term"]},{"cell_type":"markdown","metadata":{"id":"_-CcGTKgsMrY"},"source":["Implement Logistic Regression with L2 regularization Using SGD: without using sklearn\n"]},{"cell_type":"markdown","metadata":{"id":"ZR_HgjgS_wKu"},"source":["Initialize weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GecwYV9fsKZ9"},"outputs":[],"source":["#initialize the weights as 1d array consisting of all zeros similar to the dimensions of row_vector\n","#initialize bias to zero\n","\n","def initialize_weights(row_vector):\n","  if len(row_vector.shape) == 1:\n","    w = np.zeros(row_vector.shape[0])\n","  else:\n","    w = np.zeros(row_vector.shape[1])\n","  b = 0\n","  return w,b"]},{"cell_type":"markdown","metadata":{"id":"QN83oMWy_5rv"},"source":["Compute sigmoid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAfmQF47_Sd6"},"outputs":[],"source":["# compute sigmoid(z) and return\n","\n","def sigmoid(z):\n","  if type(z) == list or isinstance(z,np.ndarray):\n","    return np.array([1/(1+ float(mp.exp(-i))) for i in z])\n","  else:\n","    return 1/(1+ float(mp.exp(-z)))"]},{"cell_type":"markdown","metadata":{"id":"gS7JXbcrBOFF"},"source":["Compute loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaFDgsp3sKi6"},"outputs":[],"source":["# Define a function to calculate log loss.\n","def logloss(y_true,y_pred):\n","  if type(y_true) == list or isinstance(y_true,np.ndarray):\n","    n = len(y_true)\n","  else:\n","    n = 1\n","  loss = (-1 * (1/n) * (np.dot(np.array(y_true), np.array([0 if np.log10(m) == -inf else np.log10(m) for m in np.array(y_pred)]) ) + np.dot((1 - np.array(y_true)), np.array([0 if np.log10(1 - m) == -inf else np.log10(1 - m) for m in np.array(y_pred)]) )))\n","  return loss"]},{"cell_type":"markdown","metadata":{"id":"tQabIadLCBAB"},"source":["Compute gradient w.r.to  'w'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMVikyuFsKo5"},"outputs":[],"source":["def gradient_dw(x,y,w,b,alpha,N):\n","  dw = np.dot(np.array(x), np.array((y - sigmoid(float((np.dot(np.array(w.transpose()), np.array(x))) + b))))) - np.dot(np.array(( alpha * ( 1 / N))), np.array(w))\n","  return dw"]},{"cell_type":"markdown","metadata":{"id":"LE8g84_GI62n"},"source":["Compute gradient w.r.to 'b'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nUf2ft4EZp8"},"outputs":[],"source":["def gradient_db(x,y,w,b):\n","  db = y - sigmoid(float((np.dot(np.array(w.transpose()), np.array(x))) + b))\n","  return db"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-kTLxLmQYzc"},"outputs":[],"source":["# prediction function used to compute predicted_y given the dataset X\n","def pred(w,b, X):\n","  N = len(X)\n","  predict = []\n","  for i in range(N):\n","      z=np.dot(w,X[i])+b\n","      predict.append(sigmoid(z))\n","  return np.array(predict)"]},{"cell_type":"markdown","metadata":{"id":"TCK0jY_EOvyU"},"source":["Implementing logistic regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmAdc5ejEZ25"},"outputs":[],"source":["# In this function, we will implement logistic regression.\n","def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n","    train_loss = []\n","    mean_train_loss = []\n","    test_loss = []\n","    mean_test_loss = []\n","    y_pred_train = []\n","    y_pred_test = []\n","    w,b = initialize_weights(X_train[0])\n","    N = len(X_train)\n","    M = len(X_test)\n","    h = 0\n","    while True:\n","      if h == epochs:\n","        break\n","      for i in range(N):\n","        w += eta0 * gradient_dw(X_train[i],y_train[i],w,b,alpha,N)\n","        b += eta0 * gradient_db(X_train[i],y_train[i],w,b)\n","        y_pred_train.append(pred(w,b, [X_train[i]]))\n","        train_loss.append(logloss(y_train[i],y_pred_train[i]))\n","      for j in range(M):\n","        y_pred_test.append(pred(w,b, [X_train[j]]))\n","        test_loss.append(logloss(y_test[j],y_pred_test[j]))\n","      mean_train_loss.append(mean(train_loss))\n","      mean_test_loss.append(mean(test_loss))\n","      print('Epoch: {}   Train loss: {}   Test loss: {}'.format(h+1,mean(mean_train_loss), mean(mean_test_loss)))\n","      # if (h>0) and ((abs(mean_train_loss[h] - mean_train_loss[h-1]) < 0.005) or (h == epochs)):\n","      h += 1\n","      train_loss = []\n","      test_loss = []\n","    return w,b,mean_train_loss,mean_test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUquz7LFEZ6E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9788d63c-865f-4311-981b-839cefefaf01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 2   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 3   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 4   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 5   Train loss: 0.16485730442340443   Test loss: 0.42264641495854355\n","Epoch: 6   Train loss: 0.16485730442340443   Test loss: 0.42264641495854355\n","Epoch: 7   Train loss: 0.16485730442340443   Test loss: 0.4226464149585435\n","Epoch: 8   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 9   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 10   Train loss: 0.16485730442340446   Test loss: 0.42264641495854355\n","Epoch: 11   Train loss: 0.16485730442340446   Test loss: 0.42264641495854355\n","Epoch: 12   Train loss: 0.16485730442340446   Test loss: 0.42264641495854355\n","Epoch: 13   Train loss: 0.16485730442340446   Test loss: 0.4226464149585435\n","Epoch: 14   Train loss: 0.16485730442340446   Test loss: 0.4226464149585435\n","Epoch: 15   Train loss: 0.16485730442340443   Test loss: 0.4226464149585435\n","Epoch: 16   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 17   Train loss: 0.16485730442340443   Test loss: 0.4226464149585436\n","Epoch: 18   Train loss: 0.1648573044234044   Test loss: 0.4226464149585436\n","Epoch: 19   Train loss: 0.1648573044234044   Test loss: 0.4226464149585436\n","Epoch: 20   Train loss: 0.1648573044234044   Test loss: 0.42264641495854366\n"]}],"source":["alpha=0.001\n","eta0=0.001\n","N=len(X_train)\n","epochs=20\n","w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"]},{"cell_type":"code","source":["print(w)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gW10fb7BUfiu","outputId":"0c81a255-72db-4d06-a4f0-0f7c17e3386a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.4136237   0.19233564 -0.14998795  0.3264539  -0.22464057  0.58627918\n"," -0.42724728 -0.10046785  0.21459147  0.15533582  0.17859096 -0.01289335\n"," -0.06476848  0.36319524 -0.00993009]\n","-0.8978925579469353\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfHTyh4mvFy0","outputId":"61f3dc09-db2d-4de1-dd91-72b34f97ce37"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.42336692  0.18547565 -0.14859036  0.34144407 -0.2081867   0.56016579\n","  -0.45242483 -0.09408813  0.2092732   0.18084126  0.19705191  0.00421916\n","  -0.0796037   0.33852802  0.02266721]]\n","[-0.8531383]\n"]},{"output_type":"execute_result","data":{"text/plain":["(1, 15)"]},"metadata":{},"execution_count":129}],"source":["print(clf.coef_)\n","print(clf.intercept_)\n","clf.coef_.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSdmHO9vQYzi"},"outputs":[],"source":["# these are the results we got after we implemented sgd and found the optimal weights and intercept\n","\n","w-clf.coef_, b-clf.intercept_"]},{"cell_type":"markdown","metadata":{"id":"230YbSgNSUrQ"},"source":["Plot train and test loss vs epochs\n","\n","plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1O6GrRt7UeCJ","colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"e0cd3e47-fdc0-41da-ead9-ccd9828494be"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(list(range(1,epochs+1)),train_loss)\n","plt.xlabel('epochs')\n","plt.ylabel('train_loss')\n","plt.title('epochs v/s train_loss')\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":0}